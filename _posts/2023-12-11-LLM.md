---
layout: post
title: Large Language Models
author: [Richard Kuo]
category: [Lecture]
tags: [jekyll, ai]
---

Introduction to Language Models, LLMs, Algorithms for building LLMs, etc.

---
## History of LLM
[A Survey of Large Language Models](https://www.semanticscholar.org/paper/A-Survey-of-Large-Language-Models-Zhao-Zhou/c61d54644e9aedcfc756e5d6fe4cc8b78c87755d)<br>
Since the introduction of Transformer model in 2017, large language models (LLMs) have evolved significantly.<br>
ChatGPT saw 1.6B visits in May 2023. Meta also released three versions of LLaMA-2 (7B, 13B, 70B) free for commercial use in July.<br>

---
### å¾è§£é¡Œèƒ½åŠ›ä¾†çœ‹å››ä»£èªè¨€æ¨¡å‹çš„æ¼”é€²
An evolution process of the four generations of language models (LM) from the perspective of task solving capacity.<br>
![](https://d3i71xaburhd42.cloudfront.net/c61d54644e9aedcfc756e5d6fe4cc8b78c87755d/2-Figure2-1.png)

---
### å¤§å‹èªè¨€æ¨¡å‹çµ±è¨ˆè¡¨
![](https://d3i71xaburhd42.cloudfront.net/c61d54644e9aedcfc756e5d6fe4cc8b78c87755d/8-Table1-1.png)

---
### è¿‘å¹´å¤§å‹èªè¨€æ¨¡å‹(>10B)çš„æ™‚é–“è»¸
![](https://d3i71xaburhd42.cloudfront.net/c61d54644e9aedcfc756e5d6fe4cc8b78c87755d/9-Figure3-1.png)

---
### å¤§å‹èªè¨€æ¨¡å‹ä¹‹ç”¢æ¥­åˆ†é¡
![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2e8bfd65-5272-4cf1-8b86-954bab975bab_2400x1350.png)

---
### å¤§å‹èªè¨€æ¨¡å‹ä¹‹æŠ€è¡“åˆ†é¡
![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vZK250i8PIWid6BiaZ1QCA.png)

---
### è¨ˆç®—è¨˜æ†¶é«”çš„æˆé•·èˆ‡Transformerå¤§å°çš„é—œä¿‚
[AI and Memory Wall](https://medium.com/riselab/ai-and-memory-wall-2cb4265cb0b8)<br>
![](https://miro.medium.com/v2/resize:fit:4800/format:webp/0*U-7GJqBZ2tY1W5Iu)

---
### LLMops é‡å°ç”Ÿæˆå¼ AI ç”¨ä¾‹èª¿æ•´äº† MLops æŠ€è¡“å †ç–Š
![](https://www.insightpartners.com/wp-content/uploads/2023/10/llmops-market-map-1.png)

---
## Transformer
**Paper:** [Attention Is All You Need](https://arxiv.org/abs/1706.03762)<br>
**Code:** [huggingface/transformers](https://github.com/huggingface/transformers)<br>
![](https://miro.medium.com/max/407/1*3pxDWM3c1R_WSW7hVKoaRA.png)
<table>
<tr>
<td><iframe width="400" height="300" src="https://www.youtube.com/embed/n9TlOhRjYoc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><iframe width="400" height="300" src="https://www.youtube.com/embed/N6aRv06iv2g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
</tr>
</table>

---
### New Understanding about Transformer
**Blog:** <br>
* [Researchers Gain New Understanding From Simple AI](https://www.quantamagazine.org/researchers-glimpse-how-ai-gets-so-good-at-language-processing-20220414/)
* [Transformerç¨±éœ¸çš„åŸå› æ‰¾åˆ°äº†ï¼ŸOpenAIå‰æ ¸å¿ƒå“¡å·¥æ­é–‹æ³¨æ„åŠ›é ­å”åŒå·¥ä½œæ©Ÿç†](https://bangqu.com/A76oX7.html)

**Papers:**<br>
* [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html)
* [In-context Learning and Induction Heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)

---
### BERT
**Paper:** [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)<br>
**Blog:** [é€²æ“Šçš„BERTï¼šNLP ç•Œçš„å·¨äººä¹‹åŠ›èˆ‡é·ç§»å­¸ç¿’](https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html)<br>

---
### GPT (Generative Pre-Training Transformer)
**Paper:** [Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)<br>
**Paper:** [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)<br>
**Code:** [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)<br>
<iframe width="640" height="480" src="https://www.youtube.com/embed/WY_E0Sd4K80" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---
### GPT-2
**Paper:** [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)<br>
**Code:** [openai/gpt-2](https://github.com/openai/gpt-2)<br>
**GPT2 Demo:** [Transformer Demo](https://app.inferkit.com/demo), [GPT-2 small](https://minimaxir.com/apps/gpt2-small/)<br>
**Blog:** [ç›´è§€ç†è§£GPT2èªè¨€æ¨¡å‹ä¸¦ç”Ÿæˆé‡‘åº¸æ­¦ä¿ å°èªª](https://leemeng.tw/gpt2-language-model-generate-chinese-jing-yong-novels.html)<br>

---
### T5: Text-To-Text Transfer Transformer (by Google)
**Paper:** [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)<br>
**Code:** [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer)<br>
![](https://1.bp.blogspot.com/-89OY3FjN0N0/XlQl4PEYGsI/AAAAAAAAFW4/knj8HFuo48cUFlwCHuU5feQ7yxfsewcAwCLcBGAsYHQ/s640/image2.png)

---
### GPT-3
**Code:** [openai/gpt-3](https://github.com/openai/gpt-3)<br>
**[GPT-3 Demo](https://gpt3demo.com/)**<br>
![](https://dzlab.github.io/assets/2020/07/20200725-gpt3-model-architecture.png)

---
### [CKIP Lab ç¹é«”ä¸­æ–‡è©åº«å°çµ„](https://ckip.iis.sinica.edu.tw/)
CKIP (CHINESE KNOWLEDGE AND INFORMATION PROCESSING): ç¹é«”ä¸­æ–‡çš„ transformers æ¨¡å‹ï¼ˆåŒ…å« ALBERTã€BERTã€GPT2ï¼‰åŠè‡ªç„¶èªè¨€è™•ç†å·¥å…·ã€‚<br>
[CKIP Lab ä¸‹è¼‰è»Ÿé«”èˆ‡è³‡æº](https://ckip.iis.sinica.edu.tw/resource)<br>
* [CKIP Transformers](https://github.com/ckiplab/ckip-transformers)
* [CKIP Tagger](https://github.com/ckiplab/ckiptagger)<br>

---
## Question Answering
### [SQuAD 2.0](https://rajpurkar.github.io/SQuAD-explorer/) - The Stanford Question Answering Dataset<br>
**Paper:** [Know What You Don't Know: Unanswerable Questions for SQuAD](https://arxiv.org/abs/1806.03822)<br>
<p><img src="https://miro.medium.com/max/1400/1*Tqibs5z0zCntcK6kCpziaA.png" width="50%" height="50%"></p>

---
### Instruct GPT
**Paper:** [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)<br>
**Blog:** [Aligning Language Models to Follow Instructions](https://openai.com/blog/instruction-following/)<br>

---
### ChatGPT
[ChatGPT: Optimizing Language Models for Dialogue](https://openai.com/blog/chatgpt/)<br>
ChatGPT is fine-tuned from a model in the GPT-3.5 series, which finished training in early 2022.<br>

![](https://cdn.openai.com/chatgpt/draft-20221129c/ChatGPT_Diagram.svg)

<iframe width="640" height="455" src="https://www.youtube.com/embed/e0aKI2GGZNg" title="Chat GPT (å¯èƒ½)æ˜¯æ€éº¼ç…‰æˆçš„ - GPT ç¤¾æœƒåŒ–çš„éç¨‹" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---
### GPT4
**Paper:** [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)<br>
![](https://image-cdn.learnin.tw/bnextmedia/image/album/2023-03/img-1679884936-23656.png?w=1200&output=webp)

---
## Open LLMs
**[Open LLM leardboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)**<br>

---
### [LLaMA](https://huggingface.co/docs/transformers/main/model_doc/llama)
*It is a collection of foundation language models ranging from 7B to 65B parameters.*<br>
**Paper:** [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)<br>
![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nt-ydHhSVsaLXq_HZRaLQA.png)

---
### [OpenLLaMA](https://github.com/openlm-research/open_llama)
**model:** [https://huggingface.co/openlm-research/open_llama_3b_v2](https://huggingface.co/openlm-research/open_llama_3b_v2)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-openllama](https://www.kaggle.com/code/rkuo2000/llm-openllama)<br>

---
**Blog:** [Building a Million-Parameter LLM from Scratch Using Python](https://levelup.gitconnected.com/building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2)<br>
**Kaggle:** [LLM LLaMA from scratch](https://www.kaggle.com/rkuo2000/llm-llama-from-scratch/)<br>

---
### Pythia
**Paper:** [Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://arxiv.org/abs/2304.01373)<br>
**Dataset:** <br>
[The Pile: An 800GB Dataset of Diverse Text for Language Modeling](https://arxiv.org/abs/2101.00027)<br>
[Datasheet for the Pile](https://arxiv.org/abs/2201.07311)<br>
**Code:** [Pythia: Interpreting Transformers Across Time and Scale](https://github.com/EleutherAI/pythia)<br>

---
### Falcon-40B
**Paper:** [The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only](https://arxiv.org/abs/2306.01116)<br>
**Dataset:** [https://huggingface.co/datasets/tiiuae/falcon-refinedweb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)<br>
**Code:** [https://huggingface.co/tiiuae/falcon-40b](https://huggingface.co/tiiuae/falcon-40b)<br>

---
### LLaMA-2
**Paper:** [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)<br>
**Code:** [https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama)<br>
**models:** [https://huggingface.co/meta-llama](https://huggingface.co/meta-llama)<br>

---
### MiniGPT-4
**Paper:** [MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models](https://arxiv.org/abs/2304.10592)<br>
**Paper:** [MiniGPT-v2: Large Language Model as a Unified Interface for Vision-Language Multi-task Learning](https://arxiv.org/abs/2310.09478)<br>
**Code:** [https://github.com/Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)<br>

![](https://github.com/Vision-CAIR/MiniGPT-4/raw/main/figs/minigpt2_demo.png)
![](https://github.com/Vision-CAIR/MiniGPT-4/raw/main/figs/online_demo.png)

---
### Orca 
**Paper:** [Orca: Progressive Learning from Complex Explanation Traces of GPT-4](https://arxiv.org/abs/2306.02707)<br>

---
### LLM Lingua
**Paper: [LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://arxiv.org/abs/2310.05736)<br>
**Code: [https://github.com/microsoft/LLMLingua](https://github.com/microsoft/LLMLingua)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-lingua](https://www.kaggle.com/code/rkuo2000/llm-lingua)<br>
![](https://github.com/microsoft/LLMLingua/raw/main/images/LLMLingua.png)

---
### Mistral
**Paper:** [Mistral 7B](https://arxiv.org/abs/2310.06825)<br>
**Code:** [https://github.com/mistralai/mistral-src](https://github.com/mistralai/mistral-src)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-mistral-7b-instruct](https://www.kaggle.com/code/rkuo2000/llm-mistral-7b-instruct)<br>

---
### Mistral 8X7B
![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*91yEJMc_q-QlU-bk.png)

---
### Zephyr
**Paper:** [Zephyr: Direct Distillation of LM Alignment](https://arxiv.org/abs/2310.16944)<br>
**Code:** [https://huggingface.co/HuggingFaceH4/zephyr-7b-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-zephyr-7b](https://www.kaggle.com/code/rkuo2000/llm-zephyr-7b)<br>
![](https://i3.res.bangqu.com/farm/liang/news/2023/10/28/9e3a1a498f94b147fd57608b4beaefe0.jpg)

---
### SOLAR-10.7B ~ Depth Upscaling
**Code:** [https://huggingface.co/upstage/SOLAR-10.7B-v1.0](https://huggingface.co/upstage/SOLAR-10.7B-v1.0)<br>
Depth-Upscaled SOLAR-10.7B has remarkable performance. It outperforms models with up to 30B parameters, even surpassing the recent Mixtral 8X7B model.<br>
Leveraging state-of-the-art instruction fine-tuning methods, including supervised fine-tuning (SFT) and direct preference optimization (DPO), 
researchers utilized a diverse set of datasets for training. This fine-tuned model, SOLAR-10.7B-Instruct-v1.0, achieves a remarkable Model H6 score of 74.20, 
boasting its effectiveness in single-turn dialogue scenarios.<br>

---
### Phi-2 (Transformer with 2.7B parameters)
**Blog:** [Phi-2: The surprising power of small language models](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)<br>
**Code:** [https://huggingface.co/microsoft/phi-2](https://huggingface.co/microsoft/phi-2)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-phi-2](https://www.kaggle.com/code/rkuo2000/llm-phi-2)<br>

---
### Orca 2
**Paper:** [https://arxiv.org/abs/2311.11045](https://arxiv.org/abs/2311.11045)<br>
**model:** [Orca 2: Teaching Small Language Models How to Reason](https://huggingface.co/microsoft/Orca-2-13b)<br>
**Blog:** [Microsoft's Orca 2 LLM Outperforms Models That Are 10x Larger](https://www.infoq.com/news/2023/12/microsoft-orca-2-llm/)<br>
![](https://s4.itho.me/sites/default/files/images/1123-Orca-2-microsoft-600.png)

---
## Augment LLMs with our private data

### LlamaIndex
**Code:** [https://github.com/run-llama/llama_index](https://github.com/run-llama/llama_index)<br>
LlamaIndex (GPT Index) is a data framework for your LLM application.
* Offers data connectors to ingest your existing data sources and data formats (APIs, PDFs, docs, SQL, etc.)
* Provides ways to structure your data (indices, graphs) so that this data can be easily used with LLMs.
* Provides an advanced retrieval/query interface over your data: Feed in any LLM input prompt, get back retrieved context and knowledge-augmented output.
* Allows easy integrations with your outer application framework (e.g. with LangChain, Flask, Docker, ChatGPT, anything else).

---
### LLM embedder
**Paper:** [Retrieve Anything To Augment Large Language Models](https://arxiv.org/abs/2310.07554)<br>
**Code:** [https://github.com/FlagOpen/FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-flagembedding](https://www.kaggle.com/code/rkuo2000/llm-flagembedding)<br>
![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a4e4265-7dab-4c5d-b14f-5dfd1b270e75_746x735.png)
![](https://github.com/FlagOpen/FlagEmbedding/raw/master/FlagEmbedding/llm_embedder/imgs/llm-embedder.png)

---
### LM-Cocktail
**Paper:** [LM-Cocktail: Resilient Tuning of Language Models via Model Merging](https://arxiv.org/abs/2311.13534)<br>
**Code:** [https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail](https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail)<br>

---
### LongLoRA
**Code:** [https://github.com/dvlab-research/LongLoRA](https://github.com/dvlab-research/LongLoRA)<br>
[2023.11.19] We release a new version of LongAlpaca models, LongAlpaca-7B-16k, LongAlpaca-7B-16k, and LongAlpaca-7B-16k. <br>
![](https://github.com/dvlab-research/LongLoRA/raw/main/imgs/LongAlpaca.png)

---
### Magicoder 
**Paper:** [Magicoder: Source Code Is All You Need](https://arxiv.org/abs/2312.02120)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-magicoder](https://www.kaggle.com/code/rkuo2000/llm-magicoder)<br>
![](https://github.com/ise-uiuc/magicoder/raw/main/assets/overview.svg)

---
### [ALTER-LLM](https://tnoinkwms.github.io/ALTER-LLM/)
**Paper:** [From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"](https://arxiv.org/abs/2312.06571)<br>
<iframe width="593" height="346" src="https://www.youtube.com/embed/SAc-O5FDJ4k" title="play the metal" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
![](https://tnoinkwms.github.io/ALTER-LLM/architecture_2.png)
![](https://tnoinkwms.github.io/ALTER-LLM/feedback.png)

---
### EAGLE-LLM
**Blog:** [EAGLE: Lossless Acceleration of LLM Decoding by Feature Extrapolation](https://sites.google.com/view/eagle-llm)<br>
**Code:** [https://github.com/SafeAILab/EAGLE](https://github.com/SafeAILab/EAGLE)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/eagle-llm](https://www.kaggle.com/code/rkuo2000/eagle-llm)<br>

---
### Purple Llama CyberSecEval
**Paper:** [Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models](https://arxiv.org/abs/2312.04724)<br>
**Code:** [CybersecurityBenchmarks](https://github.com/facebookresearch/PurpleLlama/tree/main/CybersecurityBenchmarks)<br>
[meta-llama/LlamaGuard-7b](https://huggingface.co/meta-llama/LlamaGuard-7b)<br>
<table>
<tr><th>           </th><th>Our Test Set (Prompt)</th><th>OpenAI Mod</th><th>ToxicChat</th><th>Our Test Set (Response)</th></tr>
<tr><td>Llama-Guard</td><td>0.945</td><td>0.847</td><td>0.626</td><td>0.953</td></tr>
<tr><td>OpenAI API</td><td>	0.764</td><td>0.856</td><td>0.588</td><td>0.769</td></tr>
<tr><td>Perspective API</td><td>0.728</td><td>0.787</td><td>0.532</td><td>0.699</td></tr>
</table>

---
## Building LLM 
[Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/)
![](https://eugeneyan.com/assets/llm-patterns-og.png)

### [Retrieval Augmented Generation (RAG)](https://arxiv.org/abs/2005.11401) to Add Knowledge
![](https://eugeneyan.com/assets/rag.jpg)

---
#### [A Guide on 12 Tuning Strategies for Production-Ready RAG Applications](https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439#156e)
![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*tT14GpYfEMSqCjnt2UQOGQ.png)

---
#### [NLP â€¢ Retrieval Augmented Generation](https://aman.ai/primers/ai/RAG/)

---
### [Building RAG-based LLM Applications for Production](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)
![](https://images.ctfassets.net/xjan103pcp94/4PX0l1ruKqfH17YvUiMFPw/c60a7a665125cb8056bebcc146c23b76/image8.png)
(1)å°‡å¤–éƒ¨æ–‡ä»¶åšåˆ†å¡Š(chunking)å†åˆ†è©(tokenize)è½‰æˆtoken<br>
(2)åˆ©ç”¨åµŒå…¥æ¨¡å‹ï¼Œå°‡tokenåšåµŒå…¥(embeds)é‹ç®—ï¼Œè½‰æˆå‘é‡ï¼Œå„²å­˜è‡³å‘é‡è³‡æ–™åº«(Vector Database)ä¸¦ç´¢å¼•(Indexes)<br>
(3)ç”¨æˆ¶æå‡ºå•é¡Œï¼Œå‘é‡è³‡æ–™åº«å°‡å•é¡Œå­—ä¸²è½‰æˆå‘é‡(åˆ©ç”¨å‰ä¸€å€‹æ­¥é©Ÿçš„åµŒå…¥æ¨¡å‹)ï¼Œå†é€éé¤˜å¼¦(Cosine)ç›¸ä¼¼åº¦æˆ–æ­æ°è·é›¢æ¼”ç®—æ³•ä¾†æœå°‹è³‡æ–™åº«è£¡çš„è¿‘ä¼¼è³‡æ–™<br>
(4)å°‡ç”¨æˆ¶çš„å•é¡Œã€è³‡æ–™åº«æŸ¥è©¢çµæœä¸€èµ·æ”¾é€²Prompt(æç¤º)ï¼Œäº¤ç”±LLMæ¨ç†å‡ºæœ€çµ‚ç­”æ¡ˆ<br>
ä»¥ä¸Šæ˜¯åŸºæœ¬çš„RAGæµç¨‹ï¼Œåˆ©ç”¨Langchainæˆ–LlamaIndexæˆ–Haystackä¹‹é¡çš„æ‡‰ç”¨ç¨‹å¼é–‹ç™¼æ¡†æ¶ï¼Œå¤§æ¦‚ç”¨ä¸åˆ°ä¸€ç™¾è¡Œçš„ç¨‹å¼ç¢¼å°±èƒ½åšæ‰(å«LLMçš„è£è¼‰)ã€‚<br>

Anyscaleå‰›å‰›ç™¼å¸ƒçš„ä¸€ç¯‡ç²¾å½©å¥½æ–‡ï¼Œè£¡é ­ä»‹ç´¹äº†å¾ˆå¤šæå‡RAGæˆæ•ˆçš„é«˜æ®µæŠ€å·§ï¼Œå…§å®¹åŒ…æ‹¬ï¼š<br>
ğŸš€å¾é ­é–‹å§‹å»ºæ§‹åŸºæ–¼RAGçš„LLMæ‡‰ç”¨ç¨‹å¼ã€‚<br>
ğŸš€ åœ¨å…·æœ‰ä¸åŒé‹ç®—è³‡æºçš„å¤šå€‹å·¥ä½œäººå“¡ä¹‹é–“æ“´å±•ä¸»è¦å·¥ä½œè² è¼‰ï¼ˆè¼‰å…¥ã€åˆ†å¡Šã€åµŒå…¥ã€ç´¢å¼•ã€æœå‹™ç­‰ï¼‰ã€‚<br>
ğŸš€è©•ä¼°æ‡‰ç”¨ç¨‹å¼çš„ä¸åŒé…ç½®ï¼Œä»¥æœ€ä½³åŒ–æ¯å€‹å…ƒä»¶ï¼ˆä¾‹å¦‚retrieval_scoreï¼‰å’Œæ•´é«”æ•ˆèƒ½ï¼ˆquality_scoreï¼‰ã€‚<br>
ğŸš€ é€éé–‹æºå’Œé–‰æºLLMå¯¦ä½œæ··åˆä»£ç†è·¯ç”±æ–¹æ³•ï¼Œä»¥å»ºç«‹æ•ˆèƒ½æœ€ä½³ä¸”æœ€å…·æˆæœ¬æ•ˆç›Šçš„æ‡‰ç”¨ç¨‹å¼ã€‚<br>
ğŸš€ä»¥é«˜æ“´å±•æ€§èˆ‡é«˜å¯ç”¨æ€§çš„æ–¹å¼ç‚ºæ‡‰ç”¨ç¨‹å¼æä¾›æœå‹™ã€‚<br>
ğŸš€äº†è§£å¾®èª¿ã€æç¤ºå·¥ç¨‹ã€è©å½™æœå°‹(lexical search)ã€é‡æ–°æ’åã€è³‡æ–™é£›è¼ª(data flywheel)ç­‰æ–¹æ³•å¦‚ä½•å½±éŸ¿æ‡‰ç”¨ç¨‹å¼çš„æ•ˆèƒ½ã€‚<br>

---
#### [Fusion-in-Decoder (FiD)](https://arxiv.org/abs/2007.01282)
![](https://eugeneyan.com/assets/fid.jpg)

---
#### [Retrieval-Enhanced Transformer (RETRO)](https://arxiv.org/abs/2112.04426)
![](https://eugeneyan.com/assets/retro.jpg)

---
#### [Internet-augmented LMs](https://arxiv.org/abs/2203.05115)
![](https://eugeneyan.com/assets/internet-llm.jpg)

---
#### [Overview of RAG for CodeT5+](https://arxiv.org/abs/2305.07922)
![](https://eugeneyan.com/assets/codet5.jpg)

---
#### [Hypothetical document embeddings (HyDE)](https://arxiv.org/abs/2212.10496)
![](https://eugeneyan.com/assets/hyde.jpg)

---
### Fine-tuning : To get better at specific tasks

#### [ULMFit](https://arxiv.org/abs/1801.06146)
![](https://eugeneyan.com/assets/ulmfit.jpg)

---
#### [Bidirectional Encoder Representations from Transformers (BERT; encoder only)](https://arxiv.org/abs/1810.04805)
![](https://eugeneyan.com/assets/bert.jpg)

---
#### [Generative Pre-trained Transformers (GPT; decoder only)](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
![](https://eugeneyan.com/assets/gpt.jpg)

---
#### [Text-to-text Transfer Transformer (T5; encoder-decoder)](https://arxiv.org/abs/1910.10683)
![](https://eugeneyan.com/assets/t5.jpg)

---
#### [InstructGPT](https://arxiv.org/abs/2203.02155)
![](https://eugeneyan.com/assets/instructgpt.jpg)

---
#### [Soft prompt tuning](https://arxiv.org/abs/2104.08691)
**Paper:** [Soft-prompt Tuning for Large Language Models to Evaluate Bias](https://arxiv.org/abs/2306.04735)<br>
**Blog:** [Guiding Frozen Language Models with Learned Soft Prompts](https://blog.research.google/2022/02/guiding-frozen-language-models-with.html)<br>
![](https://blogger.googleusercontent.com/img/a/AVvXsEgWPnqNhC2ZtEjkumYCtNi18nHLQY9U5dmV13cJzQzscVhcHYhLdpTdTv-1ZI3IaOVfWE9x7y4g75jtyImEaI7dsonfD43S24flWsevDgEdbA0oR5w6fJsnFecnKGysSguLKJKEQ5svS-aQn_ClNZm6jURazpAxFNWTQoTm708a4hFq8f2HzMVpz3wZ_g=w640-h360)
![](https://blogger.googleusercontent.com/img/a/AVvXsEgNi-pteVLIEZ6H5HdV8RadrzCkegKA3zJCM2ObwTHKKYhgF7b-c7qsN85P1j4nXcqHcIDTj2dU5KfslYU4PuIFXaDpF6o_e5jMfFWljd6Kpc0E1n-UG6LtMA5B_BIAKjWTUibhwCnQ2zWap9BiZgA-VB0bxQG-S1jMcUHZ01kl0uLIKIoqKYH8QtUiYA=s693)

---
#### [prefix tuning](https://arxiv.org/abs/2101.00190)
![](https://eugeneyan.com/assets/prefix.jpg)

---
#### [adapter](https://arxiv.org/abs/1902.00751)
![](https://eugeneyan.com/assets/adapter.jpg)

---
#### [Low-Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685)
![](https://eugeneyan.com/assets/lora.jpg)

---
#### [QLoRA](https://arxiv.org/abs/2305.14314)
![](https://eugeneyan.com/assets/qlora.jpg)

---
### Caching: To reduce latency and cost

#### [GPTCache](https://github.com/zilliztech/GPTCache)
![](https://eugeneyan.com/assets/gptcache.jpg)

---
### LLM Kaggle-examples:
[https://www.kaggle.com/code/rkuo2000/llm-chromadb-langchain](https://www.kaggle.com/code/rkuo2000/llm-chromadb-langchain)<br>
[https://www.kaggle.com/code/rkuo2000/llm-finetuning](https://www.kaggle.com/code/rkuo2000/llm-finetuning/)<br>
[https://www.kaggle.com/code/rkuo2000/llama2-7b-hf-finetune](https://www.kaggle.com/code/rkuo2000/llama2-7b-hf-finetune)<br>
[https://www.kaggle.com/code/rkuo2000/llama2-qlora](https://www.kaggle.com/code/rkuo2000/llama2-qlora)<br>

---
### [Open-LLMs](https://github.com/eugeneyan/open-llms)
Open LLMs<br>
Open LLM for Coder<br>

---
## LLM Coders

### AlphaCode
**Paper:** [Competition-Level Code Generation with AlphaCode](https://arxiv.org/pdf/2203.07814.pdf)<br>
![](https://victordibia.com/static/alphacode-2292e53c73500c1103f2f1fccec3f33d.png)

---
### AlphaCode 2
**Report:** [AlphaCode 2 Technical Report](https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf)<br>
![](https://cdn.bulldogjob.com/system/photos/files/000/013/124/original/AlphaCode_2_overview.png)

---
### StarCoder
**Paper:** [StarCoder: may the source be with you!](https://arxiv.org/abs/2305.06161)<br>
The StarCoder models are 15.5B parameter models trained on **80+** programming languages from The Stack (v1.2), with opt-out requests excluded. The model uses Multi Query Attention, a context window of 8192 tokens, and was trained using the Fill-in-the-Middle objective on 1 trillion tokens.<br>

---
### StarChat-Alpha
**Blog:** [Creating a Coding Assistant with StarCoder](https://huggingface.co/blog/starchat-alpha)<br>

---
### DeciCoder
**Blog:** [Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation](https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/)<br>

---
### CodeGen2.5
**Blog:** [CodeGen2.5: Small, but mighty](https://blog.salesforceairesearch.com/codegen25/)<br>
**Paper:** [CodeGen2: Lessons for Training LLMs on Programming and Natural Languages](https://arxiv.org/abs/2305.02309)<br>
**Code:** [https://github.com/salesforce/CodeGen/tree/main/codegen25](https://github.com/salesforce/CodeGen/tree/main/codegen25)<br>

---
### Code Llama
**Paper:** [Code Llama: Open Foundation Models for Code](https://arxiv.org/abs/2308.12950)<br>
![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*0wXBmrJYzHnTvIupJL_TeQ.png)
**Kaggle:** [https://www.kaggle.com/rkuo2000/llm-code-llama](https://www.kaggle.com/rkuo2000/llm-code-llama)<br>

---
## Thoughts

### Tree of Thoughts
**Paper:** [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)<br>
**Code:** [https://github.com/princeton-nlp/tree-of-thought-llm](https://github.com/princeton-nlp/tree-of-thought-llm)<br>
![](https://github.com/princeton-nlp/tree-of-thought-llm/blob/master/pics/teaser.png?raw=true)

---
### XoT
**Paper:** [Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation](https://arxiv.org/abs/2311.04254)<br>
![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*r_a44DuxG3D8DGZO.png)

---
### FunSearch
[DeepMindç™¼å±•ç”¨LLMè§£å›°é›£æ•¸å­¸å•é¡Œçš„æ–¹æ³•](https://www.ithome.com.tw/news/160354)<br>
![](https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/2108_-_funsearch_making_new_discoveries_in_mathematical_sciences_using_lar_-_deepmind.google.jpg?itok=mAy4ydAE)

---
### BrainGPT
**Paper:** [DeWave: Discrete EEG Waves Encoding for Brain Dynamics to Text Translation](https://arxiv.org/abs/2309.14030)<br>
**Blog:** [New Mind-Reading "BrainGPT" Turns Thoughts Into Text On Screen](https://www.iflscience.com/new-mind-reading-braingpt-turns-thoughts-into-text-on-screen-72054)<br>
![](https://i3.res.bangqu.com/farm/liang/news/2023/12/18/339b9a2158e1fd28e1e39ee4b1557df2.jpg)
![](https://i3.res.bangqu.com/farm/liang/news/2023/12/18/79ca704627e4cadc1e23afc1b2f029cb.jpg)
<iframe width="993" height="559" src="https://www.youtube.com/embed/crJst7Yfzj4" title="UTS HAI Research - BrainGPT" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

---
### [Run Llama 2 Locally in 7 Lines! (Apple Silicon Mac)](https://blog.lastmileai.dev/run-llama-2-locally-in-7-lines-apple-silicon-mac-c3f46143f327)
![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*81Zzsz8opkq8eBUbpRHlng.png)
On an `M2 Max MacBook Pro`, I was able to get 35â€“40 tokens per second using the LLAMA_METAL build flag.<br>

### [LLaMA-2-7B Benchmark](https://github.com/liltom-eth/llama2-webui/blob/main/docs/performance.md)


<br>
<br>

*This site was last updated {{ site.time | date: "%B %d, %Y" }}.*

